from sklearn.datasets import fetch_20newsgroups
from sklearn.decomposition import TruncatedSVD
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import Normalizer
from sklearn import metrics
from sklearn.cluster import* 
from time import time
import numpy as np
from sklearn import mixture

# #############################################################################
# Load some categories from the training set
categories = [
    'alt.atheism',
    'talk.religion.misc',
    'comp.graphics',
    'sci.space',
]
dataset = fetch_20newsgroups(subset='all', categories=categories,shuffle=True, random_state=42)
print("%d documents" % len(dataset.data))
print("%d categories" % len(dataset.target_names))
print()

labels = dataset.target
true_k = np.unique(labels).shape[0]

vectorizer = TfidfVectorizer(max_df=0.5, max_features=10000, min_df=2, stop_words='english', use_idf=True)
X = vectorizer.fit_transform(dataset.data)
# Vectorizer results are normalized, which makes KMeans behave as
# spherical k-means for better results. Since LSA/SVD results are
# not normalized, we have to redo the normalization.
svd = TruncatedSVD(10)
normalizer = Normalizer(copy=False)
lsa = make_pipeline(svd, normalizer)
X = lsa.fit_transform(X)
#################################################
#OUT
print('%-30s\t%s\t%s\t%s\t%s' % ('', 'TIME', 'HOM', 'COM', 'NMI'))
def Output_result(labels_true,labels_pred,name):
    print('%-30s\t%.2fs\t%.3f\t%.3f\t%.3f' % (name,(time() - t0),
          metrics.homogeneity_score(labels_true,labels_pred),metrics.completeness_score(labels_true, labels_pred),metrics.normalized_mutual_info_score(labels_true, labels_pred)))
# #############################################################################
# Do the actual clustering
km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1,verbose=False)
t0 = time()
km.fit(X)
Output_result(labels,km.labels_,'KMeans')

af = AffinityPropagation()
t0 = time()
af.fit(X)
Output_result(labels,af.labels_,'AffinityPropagation')

mf = MeanShift()
t0 = time()
mf.fit(X)
Output_result(labels,mf.labels_,'MeanShit')

sc = SpectralClustering(n_clusters=true_k)
t0 = time()
sc.fit(X)
Output_result(labels,sc.labels_,'SpectralClustering')

ac = AgglomerativeClustering(n_clusters=true_k)
t0 = time()
ac.fit(X)
Output_result(labels,ac.labels_,'AgglomerativeClustering')

db = DBSCAN(eps=3, min_samples=5)
t0 = time()
db.fit(X)
Output_result(labels,db.labels_,'DBSCAN')

t0 = time()
gm = mixture.GaussianMixture(n_components=true_k).fit(X)
Output_result(labels,gm.predict(X),'GaussianMixture')

